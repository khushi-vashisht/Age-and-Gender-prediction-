{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9812,"sourceType":"datasetVersion","datasetId":5793},{"sourceId":11874065,"sourceType":"datasetVersion","datasetId":7462291}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns # For confusion matrix plotting\nimport librosa\nimport librosa.display\nimport joblib # Not strictly needed for gender if no encoder was used for it\nimport tensorflow as tf\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n# from tensorflow.keras.utils import to_categorical # Not needed for binary gender true labels\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# --- PATHS ---\n# Path to the Common Voice dataset (added as input to this notebook)\nCOMMON_VOICE_DATASET_ROOT = \"/kaggle/input/common-voice/\"\n\n# Path to YOUR UPLOADED MODEL ARTIFACTS DATASET\n# This should be the dataset where your 'best_gender_model_cnn.h5' is stored.\n# Assuming it's the same dataset as your age model, or a different one if you uploaded separately.\n# Replace 'your-gender-model-dataset-slug' with the actual slug.\n# If it's in the SAME dataset as the age model:\nYOUR_MODEL_DATASET_SLUG = \"gender-model-cnn\" # Or your specific gender model dataset slug\nMODEL_ARTIFACTS_PATH = f\"/kaggle/input/{YOUR_MODEL_DATASET_SLUG}/\"\n\n\n# Paths for metadata CSVs from Common Voice dataset\nCOMMON_VOICE_METADATA_TEST_CSV = os.path.join(COMMON_VOICE_DATASET_ROOT, \"cv-valid-test.csv\")\n\n# Path to the ACTUAL AUDIO FILES DIRECTORY for the test set\nACTUAL_AUDIO_TEST_CLIPS_PATH = os.path.join(COMMON_VOICE_DATASET_ROOT, \"cv-valid-test\", \"cv-valid-test\")\n\n# --- Verification ---\nprint(f\"Path to your uploaded model artifacts: {MODEL_ARTIFACTS_PATH}\")\nprint(f\"  - Exists: {os.path.exists(MODEL_ARTIFACTS_PATH)}\")\nif os.path.exists(MODEL_ARTIFACTS_PATH):\n    print(f\"  - Contents: {os.listdir(MODEL_ARTIFACTS_PATH)}\")\n\nprint(f\"Test Metadata CSV: {COMMON_VOICE_METADATA_TEST_CSV} - Exists: {os.path.exists(COMMON_VOICE_METADATA_TEST_CSV)}\")\nprint(f\"Actual Test Audio Clips Path: {ACTUAL_AUDIO_TEST_CLIPS_PATH} - Exists: {os.path.exists(ACTUAL_AUDIO_TEST_CLIPS_PATH)}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Parameters for spectrogram (should match those used during training the gender model)\nSR = 22050\nN_FFT = 2048\nHOP_LENGTH = 512\nN_MELS = 128\nMAX_FRAMES = 256 # Max frames to ensure fixed size input\n\ndef audio_to_melspectrogram(filepath, sr=SR, n_fft=N_FFT, hop_length=HOP_LENGTH, n_mels=N_MELS, max_frames=MAX_FRAMES):\n    try:\n        audio, _ = librosa.load(filepath, sr=sr)\n        mel_spec = librosa.feature.melspectrogram(y=audio, sr=sr, n_fft=n_fft, hop_length=hop_length, n_mels=n_mels)\n        log_mel_spec = librosa.power_to_db(mel_spec, ref=np.max)\n\n        if log_mel_spec.shape[1] < max_frames:\n            pad_width = max_frames - log_mel_spec.shape[1]\n            log_mel_spec = np.pad(log_mel_spec, pad_width=((0, 0), (0, pad_width)), mode='constant', constant_values=-80)\n        else:\n            log_mel_spec = log_mel_spec[:, :max_frames]\n        return log_mel_spec\n    except Exception as e:\n        print(f\"Error generating spectrogram for {filepath}: {e}\")\n        return None\n\nprint(\"Spectrogram parameters and function defined.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def load_and_prepare_test_metadata_for_gender(csv_path, base_audio_path_root):\n    try:\n        df_meta = pd.read_csv(csv_path)\n        print(f\"Loaded {os.path.basename(csv_path)} with shape: {df_meta.shape}\")\n    except FileNotFoundError:\n        print(f\"ERROR: CSV file not found at {csv_path}.\")\n        return pd.DataFrame()\n\n    # Keep 'age' for potential filtering or context, but primary focus is gender\n    df_meta_cleaned = df_meta[['filename', 'age', 'gender']].copy()\n    df_meta_cleaned.dropna(subset=['age', 'gender'], inplace=True) # Ensure both are present for consistency\n\n    # Map gender to numeric (0 for female, 1 for male)\n    df_meta_cleaned['gender_numeric_true'] = df_meta_cleaned['gender'].map({'female': 0, 'male': 1})\n    # Drop rows where gender mapping might have failed (e.g., 'other' gender if not handled)\n    df_meta_cleaned.dropna(subset=['gender_numeric_true'], inplace=True)\n    df_meta_cleaned['gender_numeric_true'] = df_meta_cleaned['gender_numeric_true'].astype(int)\n\n\n    # Construct full audio path\n    def construct_actual_path(csv_filename_entry):\n        parts = csv_filename_entry.split('/')\n        if len(parts) == 2: # e.g., 'cv-valid-test/sample-xxxxx.mp3'\n            return os.path.join(COMMON_VOICE_DATASET_ROOT, parts[0], parts[0], parts[1])\n        return os.path.join(COMMON_VOICE_DATASET_ROOT, csv_filename_entry) # Fallback\n\n    df_meta_cleaned['full_audio_path'] = df_meta_cleaned['filename'].apply(construct_actual_path)\n\n    # Validate file existence\n    original_count = len(df_meta_cleaned)\n    df_meta_cleaned = df_meta_cleaned[df_meta_cleaned['full_audio_path'].apply(os.path.exists)].copy()\n    print(f\"Path validation: {len(df_meta_cleaned)} audio files found out of {original_count} entries.\")\n\n    print(f\"Shape after processing for gender: {df_meta_cleaned.shape}\")\n\n    return df_meta_cleaned[['filename', 'gender', 'full_audio_path', 'gender_numeric_true']].reset_index(drop=True)\n\n\n# Load test data and prepare it for gender evaluation\ndf_test_eval_gender = load_and_prepare_test_metadata_for_gender(COMMON_VOICE_METADATA_TEST_CSV,\n                                                                ACTUAL_AUDIO_TEST_CLIPS_PATH)\nif not df_test_eval_gender.empty:\n    print(\"\\nTest Data for Gender Evaluation (Head):\")\n    print(df_test_eval_gender.head())\nelse:\n    print(\"df_test_eval_gender is empty after processing.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# MODEL_ARTIFACTS_PATH is defined in Cell 1\ngender_model_path_h5 = os.path.join(MODEL_ARTIFACTS_PATH, \"best_gender_model_cnn.h5\") # Ensure this filename is correct\n\nloaded_gender_model_cnn = None\ngender_model_loaded_for_pred = False\ngender_display_map_dl = {0: \"female\", 1: \"male\"} # For displaying predictions\n\ntry:\n    if os.path.exists(gender_model_path_h5):\n        loaded_gender_model_cnn = tf.keras.models.load_model(gender_model_path_h5)\n        print(f\"Loaded gender model from: {gender_model_path_h5}\")\n        # loaded_gender_model_cnn.summary() # Optional\n        gender_model_loaded_for_pred = True\n    else:\n        print(f\"Gender model file not found at: {gender_model_path_h5}\")\n        print(f\"Please ensure the file 'best_gender_model_cnn.h5' is present in your dataset: {MODEL_ARTIFACTS_PATH}\")\n\n    if gender_model_loaded_for_pred:\n        print(\"\\nGender model is ready for prediction.\")\n    else:\n        print(\"\\nGender model failed to load. Predictions cannot be made.\")\n\nexcept Exception as e:\n    print(f\"Error loading gender model: {e}\")\n    gender_model_loaded_for_pred = False","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_true_gender_indices = []\ny_pred_gender_indices = []\ny_pred_gender_labels_examples = [] # For viewing some predictions\ntrue_gender_labels_examples = []\n\nif gender_model_loaded_for_pred and not df_test_eval_gender.empty:\n    print(f\"\\nStarting GENDER predictions on {len(df_test_eval_gender)} test samples...\")\n    \n    # Decide how many samples to predict on. For full evaluation, use the whole df_test_eval_gender.\n    # df_to_predict_gender = df_test_eval_gender.sample(n=min(100, len(df_test_eval_gender)), random_state=42) # Sample for speed\n    df_to_predict_gender = df_test_eval_gender # Predict on all available test samples\n    print(f\"Predicting on {len(df_to_predict_gender)} files for gender evaluation.\")\n\n    for index, row in df_to_predict_gender.iterrows():\n        audio_filepath = row['full_audio_path']\n        true_gender_numeric = row['gender_numeric_true'] # This is 0 or 1\n        true_gender_str = row['gender'] # This is 'female' or 'male'\n\n        mel_spec = audio_to_melspectrogram(audio_filepath)\n        if mel_spec is None:\n            print(f\"Skipping {audio_filepath} due to spectrogram error.\")\n            continue\n\n        spectrogram_reshaped = np.expand_dims(mel_spec, axis=0)       # Add batch dim\n        spectrogram_reshaped = np.expand_dims(spectrogram_reshaped, axis=-1) # Add channel dim\n\n        try:\n            gender_prob = loaded_gender_model_cnn.predict(spectrogram_reshaped, verbose=0)\n            predicted_gender_idx = 1 if gender_prob[0][0] > 0.5 else 0 # Threshold sigmoid output\n\n            y_true_gender_indices.append(int(true_gender_numeric))\n            y_pred_gender_indices.append(predicted_gender_idx)\n            \n            if len(y_pred_gender_labels_examples) < 10: # Print a few examples\n                 predicted_gender_label_str = gender_display_map_dl.get(predicted_gender_idx, \"unknown\")\n                 y_pred_gender_labels_examples.append(predicted_gender_label_str)\n                 true_gender_labels_examples.append(true_gender_str)\n\n        except Exception as e:\n            print(f\"Error predicting gender for {audio_filepath}: {e}\")\n    \n    print(\"\\nExample Gender Predictions (True vs. Predicted):\")\n    for true_label, pred_label in zip(true_gender_labels_examples, y_pred_gender_labels_examples):\n        print(f\"True: {true_label:<10} | Predicted: {pred_label}\")\n    print(f\"\\nGender predictions completed on {len(y_pred_gender_indices)} files.\")\n\nelse:\n    if not gender_model_loaded_for_pred:\n        print(\"Gender model not loaded. Cannot perform batch predictions.\")\n    if df_test_eval_gender.empty:\n        print(\"df_test_eval_gender is empty. Cannot perform batch predictions.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if gender_model_loaded_for_pred and y_true_gender_indices and y_pred_gender_indices:\n    print(\"\\n--- Gender Model Evaluation Metrics ---\")\n\n    # Overall Accuracy\n    accuracy_gender = accuracy_score(y_true_gender_indices, y_pred_gender_indices)\n    print(f\"Overall Gender Accuracy: {accuracy_gender:.4f}\")\n\n    # Classification Report\n    gender_class_names = [gender_display_map_dl[0], gender_display_map_dl[1]] # e.g., ['female', 'male']\n    \n    try:\n        report_gender = classification_report(y_true_gender_indices, y_pred_gender_indices,\n                                              labels=[0, 1], # Explicitly for binary\n                                              target_names=gender_class_names,\n                                              zero_division=0)\n        print(\"\\nGender Classification Report:\")\n        print(report_gender)\n    except ValueError as ve:\n        print(f\"\\nCould not generate full gender classification report: {ve}\")\n        # This is less likely for binary if predictions are made, but good to have\n        unique_labels_gender = np.unique(y_true_gender_indices + y_pred_gender_indices)\n        if len(unique_labels_gender) > 0:\n             report_subset_gender = classification_report(y_true_gender_indices, y_pred_gender_indices,\n                                                       labels=unique_labels_gender,\n                                                       target_names=[gender_display_map_dl[i] for i in unique_labels_gender],\n                                                       zero_division=0)\n             print(\"Showing report for available gender labels:\\n\", report_subset_gender)\n        else:\n            print(\"No predictions available to generate a report.\")\n\n\n    # Confusion Matrix\n    cm_gender = confusion_matrix(y_true_gender_indices, y_pred_gender_indices, labels=[0, 1])\n    plt.figure(figsize=(6, 5))\n    sns.heatmap(cm_gender, annot=True, fmt='d', cmap='Blues',\n                xticklabels=gender_class_names,\n                yticklabels=gender_class_names)\n    plt.xlabel('Predicted Gender')\n    plt.ylabel('True Gender')\n    plt.title('Confusion Matrix for Gender Prediction')\n    plt.show()\nelse:\n    print(\"Not enough data or gender model not loaded for evaluation.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}